<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="https://website.jingxiqiu.com/feed_style.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <tabi:metadata xmlns:tabi="https://github.com/welpo/tabi">
        <tabi:base_url>https:&#x2F;&#x2F;website.jingxiqiu.com</tabi:base_url>
        <tabi:separator>
            ‚Ä¢
        </tabi:separator>
        <tabi:about_feeds>This is a web feed, also known as an Atom feed. Subscribe by copying the URL from the address bar into your newsreader. Visit About Feeds to learn more and get started. It&#x27;s free.</tabi:about_feeds>
        <tabi:visit_the_site>Visit website</tabi:visit_the_site>
        <tabi:recent_posts>Recent posts</tabi:recent_posts>
        <tabi:last_updated_on>Updated on $DATE</tabi:last_updated_on>
        <tabi:default_theme></tabi:default_theme>
        <tabi:post_listing_date>date</tabi:post_listing_date>
        <tabi:current_section>Jingxi Qiu</tabi:current_section>
    </tabi:metadata><title>Jingxi Qiu</title>
        <subtitle>A personal blog by Jingxi Qiu</subtitle>
    <link href="https://website.jingxiqiu.com/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://website.jingxiqiu.com" rel="alternate" type="text/html"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    
    
    <updated>2025-07-01T00:00:00Z</updated>
    <id>https://website.jingxiqiu.com/atom.xml</id><entry xml:lang="en">
        <title>Migrating from NotionNext to Zola: Migration Notes</title>
        <published>2025-07-01T00:00:00+00:00</published>
        <updated>2025-07-01T00:00:00+00:00</updated>
        <author>
            <name>Jingxi Qiu</name>
        </author>
        <link rel="alternate" href="https://website.jingxiqiu.com/blog/zola-migration/" type="text/html"/>
        <id>https://website.jingxiqiu.com/blog/zola-migration/</id>
        
            <content type="html">&lt;p&gt;Reasons for Migration, Operation Scripts, Common Error Fixes‚Ä¶&lt;&#x2F;p&gt;
&lt;h1 id=&quot;migrating-from-notionnext-to-zola&quot;&gt;Migrating from NotionNext to Zola&lt;&#x2F;h1&gt;
&lt;p&gt;Recently, I migrated my personal website from NotionNext to Zola and would like to share some thoughts.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;experience-with-notionnext&quot;&gt;Experience with NotionNext&lt;&#x2F;h3&gt;
&lt;p&gt;Previously, I used NotionNext to host my personal blog. Notion is indeed an excellent text editing tool‚Äîwriting articles is smooth, and having a cross-platform app for instant writing and syncing is very convenient. As long as you set an article to ‚Äúpublished,‚Äù it appears on the frontend.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;reasons-for-migration&quot;&gt;Reasons for Migration&lt;&#x2F;h3&gt;
&lt;p&gt;As the number of articles grew, managing them with NotionNext became less efficient for me. The Notion database became large and difficult to maintain. Since I have frontend development experience, managing the frontend with CSS in static site generators like Zola is more intuitive and convenient than editing in Notion. For better article management, content customization, and multilingual support, I decided to migrate my blog to Zola.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;migration-process&quot;&gt;Migration Process&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;installing-zola&quot;&gt;Installing Zola&lt;&#x2F;h3&gt;
&lt;p&gt;The &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.getzola.org&#x2F;documentation&#x2F;getting-started&#x2F;installation&#x2F;&quot;&gt;official Zola documentation&lt;&#x2F;a&gt; is clear and straightforward. Setting up a local Zola development environment usually takes just one command. Note: If you need support for Chinese&#x2F;Japanese, you must build a custom binary index; otherwise, site search won‚Äôt work for those languages. For local installation and GitHub Actions compilation with Chinese support, see my article: &lt;a href=&quot;#&quot;&gt;Enable Chinese Indexing in Zola&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;My setup is local Windows development with deployment on GitHub Pages. The blog code is in repository A, deployed via GitHub Actions to public repository B, and then pushed to GitHub Pages.


&lt;noscript&gt;
    &lt;strong&gt;‚ö†Ô∏è JavaScript is required to render the diagram.&lt;&#x2F;strong&gt;
&lt;&#x2F;noscript&gt;
&lt;pre class=&quot;mermaid invertible-image&quot;&gt;
    flowchart TD
    %% ---- Nodes ----
    subgraph Local[&quot;Local Development&quot;]
        W[Windows Local Development]
    end

    subgraph GitHub[&quot;GitHub&quot;]
        A[Repo AÔºàBlog Source CodeÔºâ]
        GA[GitHub ActionsÔºàCI&#x2F;CDÔºâ]
        B[Repo BÔºàStatic Site FilesÔºâ]
        GP[GitHub PagesÔºàOnline HostingÔºâ]
    end

    U[Visitor &#x2F; Browser]

    %% ---- Connections ----
    W  --&gt;|git push| A
    A  --&gt;|trigger workflow| GA
    GA --&gt;|build static files ‚Üí push| B
    B  --&gt;|gh-pages branch| GP
    U  --&gt;|HTTPS request| GP

    %% ---- Styles (optional) ----
    classDef local  fill:#e5e5e5,stroke:#888,stroke-width:1px,rx:6,ry:6;
    classDef repo   fill:#fef6e4,stroke:#a9a9a9,stroke-width:1px,rx:6,ry:6;
    classDef action fill:#cbf3f0,stroke:#0096c7,stroke-width:1px,rx:6,ry:6;
    classDef page   fill:#ffd6a5,stroke:#ff8800,stroke-width:1px,rx:6,ry:6;

    class W local;
    class A,B repo;
    class GA action;
    class GP page;

    linkStyle default stroke-width:2px;
&lt;&#x2F;pre&gt;
&lt;&#x2F;p&gt;
&lt;h3 id=&quot;article-structure-multilingual-support&quot;&gt;Article Structure - Multilingual Support&lt;&#x2F;h3&gt;
&lt;p&gt;Normally, your blog can use the following structure:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;text&quot; class=&quot;language-text z-code&quot;&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;content&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;‚îî‚îÄ‚îÄ blog&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îú‚îÄ‚îÄ 2025-07-01-zola-migration.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îú‚îÄ‚îÄ 2025-06-20-new-feature.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îî‚îÄ‚îÄ 2025-05-10-performance-tips.md
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;However, for multilingual support, you need to create corresponding language files. For example, if your site‚Äôs main language is English (&lt;code&gt;en&lt;&#x2F;code&gt;) and you want to support Chinese (&lt;code&gt;zh&lt;&#x2F;code&gt;), create an &lt;code&gt;index.zh.md&lt;&#x2F;code&gt; file for the Chinese version. My structure looks like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;text&quot; class=&quot;language-text z-code&quot;&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;content&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;‚îî‚îÄ‚îÄ blog&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îú‚îÄ‚îÄ 2025-07-01-zola-migration&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îÇ   ‚îú‚îÄ‚îÄ index.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îÇ   ‚îî‚îÄ‚îÄ index.zh.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îú‚îÄ‚îÄ 2025-06-20-new-feature&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îÇ   ‚îú‚îÄ‚îÄ index.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îÇ   ‚îî‚îÄ‚îÄ index.zh.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;    ‚îî‚îÄ‚îÄ 2025-05-10-performance-tips&#x2F;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;        ‚îú‚îÄ‚îÄ index.md
&lt;&#x2F;span&gt;&lt;span class=&quot;z-text z-plain&quot;&gt;        ‚îî‚îÄ‚îÄ index.zh.md
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This way, Zola recognizes both English (default) and Chinese versions under &lt;code&gt;2025-07-01-zola-migration&lt;&#x2F;code&gt;. If a language version is missing, it won‚Äôt cause errors, but the article won‚Äôt appear in that language.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;article-migration&quot;&gt;Article Migration&lt;&#x2F;h3&gt;
&lt;p&gt;Currently, I manually export articles from NotionNext as markdown and then edit them in Zola. In the future, I may consider automating the process from Notion editor to markdown.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Documenting the complete process of migrating the personal site from NotionNext to Zola</summary>
        </entry><entry xml:lang="en">
        <title>Poetry installation and usage</title>
        <published>2024-09-22T00:00:00+00:00</published>
        <updated>2024-09-22T00:00:00+00:00</updated>
        <author>
            <name>Jingxi Qiu</name>
        </author>
        <link rel="alternate" href="https://website.jingxiqiu.com/blog/poetry-install-and-usage/" type="text/html"/>
        <id>https://website.jingxiqiu.com/blog/poetry-install-and-usage/</id>
        
            <content type="html">&lt;h1 id=&quot;using-poetry&quot;&gt;Using Poetry&lt;&#x2F;h1&gt;
&lt;!-- 
type: Post
status: Published
date: 2024&#x2F;09&#x2F;22
tags: Poetry, Python, Learning --&gt;
&lt;aside&gt;
üòÄ A simple note on poetry usage and some documentation details
&lt;&#x2F;aside&gt;
&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;&#x2F;h2&gt;
&lt;p&gt;The official installation guide is very well written, and it is recommended to install via pipx. Installing Poetry generally should not pose any problems, as long as pipx is working properly.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;python-poetry.org&#x2F;docs&#x2F;#installing-with-pipx&quot;&gt;Official Installation Guide&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;basic-usage&quot;&gt;Basic Usage&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;create-a-project&quot;&gt;Create a Project&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;code&gt;poetry new poetry-demo&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Poetry assumes your package contains a package with the same name as &lt;strong&gt;&lt;code&gt;tool.poetry.name&lt;&#x2F;code&gt;&lt;&#x2F;strong&gt; located in the root of your project. If this is not the case, populate &lt;strong&gt;&lt;code&gt;tool.poetry.packages&lt;&#x2F;code&gt;&lt;&#x2F;strong&gt; to specify your packages and their locations.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;In the pyproject.toml file, the &lt;code&gt;tool.poetry.name&lt;&#x2F;code&gt; must match the name value. If they differ, you need to specify it using &lt;code&gt;tool.poetry.packages&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For example:&lt;&#x2F;p&gt;
&lt;p&gt;Project structure:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;my_project&#x2F;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;‚îú‚îÄ‚îÄ&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; my_project&#x2F;  &lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-comment z-begin z-shell&quot;&gt;#&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt; This is the directory where your package code is located&lt;&#x2F;span&gt;&lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;‚îÇ&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt;   ‚îú‚îÄ‚îÄ __init__.py  &lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-comment z-begin z-shell&quot;&gt;#&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt; Makes it a package&lt;&#x2F;span&gt;&lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;‚îÇ&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt;   ‚îú‚îÄ‚îÄ some_module.py&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;‚îî‚îÄ‚îÄ&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; pyproject.toml&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ol&gt;
&lt;li&gt;Same as the name&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml z-code&quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-begin z-toml&quot;&gt;[&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-tag z-table z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;tool&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-end z-toml&quot;&gt;]&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-meta z-tag z-key z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-tag z-toml&quot;&gt;name&lt;&#x2F;span&gt;&lt;&#x2F;span&gt; &lt;span class=&quot;z-punctuation z-definition z-key-value z-toml&quot;&gt;=&lt;&#x2F;span&gt; &lt;span class=&quot;z-string z-quoted z-double z-basic z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;my_project&lt;span class=&quot;z-punctuation z-definition z-string z-end z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Different from the name, specify with tool.poetry.packages&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml z-code&quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-begin z-toml&quot;&gt;[&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-tag z-table z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;tool&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-end z-toml&quot;&gt;]&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-meta z-tag z-key z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-tag z-toml&quot;&gt;name&lt;&#x2F;span&gt;&lt;&#x2F;span&gt; &lt;span class=&quot;z-punctuation z-definition z-key-value z-toml&quot;&gt;=&lt;&#x2F;span&gt; &lt;span class=&quot;z-string z-quoted z-double z-basic z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;my_project&lt;span class=&quot;z-punctuation z-definition z-string z-end z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-begin z-toml&quot;&gt;[&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-tag z-table z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;tool&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;packages&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-end z-toml&quot;&gt;]&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-meta z-tag z-key z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-tag z-toml&quot;&gt;include&lt;&#x2F;span&gt;&lt;&#x2F;span&gt; &lt;span class=&quot;z-punctuation z-definition z-key-value z-toml&quot;&gt;=&lt;&#x2F;span&gt; &lt;span class=&quot;z-string z-quoted z-double z-basic z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;src&lt;span class=&quot;z-punctuation z-definition z-string z-end z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;existing-project-managed-with-poetry&quot;&gt;Existing Project Managed with Poetry&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-support z-function z-cd z-shell&quot;&gt;cd&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; pre-existing-project&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; init&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;poetry-dependencies&quot;&gt;Poetry Dependencies&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;adding-dependencies&quot;&gt;Adding Dependencies&lt;&#x2F;h3&gt;
&lt;ol&gt;
&lt;li&gt;Modify the toml file&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml z-code&quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-begin z-toml&quot;&gt;[&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-tag z-table z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;tool&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;dependencies&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-end z-toml&quot;&gt;]&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-meta z-tag z-key z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-tag z-toml&quot;&gt;pendulum&lt;&#x2F;span&gt;&lt;&#x2F;span&gt; &lt;span class=&quot;z-punctuation z-definition z-key-value z-toml&quot;&gt;=&lt;&#x2F;span&gt; &lt;span class=&quot;z-string z-quoted z-double z-basic z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;^2.1&lt;span class=&quot;z-punctuation z-definition z-string z-end z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Use the command line add (this will automatically run install)&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; add pendulum&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;supported-dependency-formats-in-poetry&quot;&gt;Supported Dependency Formats in Poetry&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;caret&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;e.g. &lt;code&gt;^1.2.3&lt;&#x2F;code&gt; ‚Üí &lt;code&gt;&amp;gt;=1.2.3 &amp;lt;2.0.0&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;tilde&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;e.g. &lt;code&gt;~1.2.3&lt;&#x2F;code&gt; ‚Üí &lt;code&gt;&amp;gt;=1.2.3 &amp;lt;1.3.0&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;wildcard&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;e.g. &lt;code&gt;1.*&lt;&#x2F;code&gt; ‚Üí &lt;code&gt;&amp;gt;=1.0.0 &amp;lt;2.0.0&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Inequality&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;e.g. &lt;code&gt;&amp;gt;= 1.2.0&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When using &lt;code&gt;poetry add&lt;&#x2F;code&gt;, you can use the &lt;code&gt;@&lt;&#x2F;code&gt; symbol, which is equivalent to &lt;code&gt;==&lt;&#x2F;code&gt;, but you can also utilize Poetry‚Äôs modifiers&lt;&#x2F;p&gt;
&lt;p&gt;e.g.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; add django@^4.0.0&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; add django@latest&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; add django&lt;span class=&quot;z-keyword z-control z-regexp z-set z-begin z-shell&quot;&gt;[&lt;&#x2F;span&gt;bcrypt&lt;span class=&quot;z-keyword z-control z-regexp z-set z-end z-shell&quot;&gt;]&lt;&#x2F;span&gt;@^4.0.0&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;managing-dependencies&quot;&gt;Managing Dependencies&lt;&#x2F;h3&gt;
&lt;p&gt;Poetry offers dependency groups to manage project dependencies, such as those used only for tests.&lt;&#x2F;p&gt;
&lt;p&gt;You can declare a dependency group using &lt;code&gt;tool.poetry.group.&amp;lt;group&amp;gt;&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;For example:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;[tool.poetry.group.test]  &lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-comment z-begin z-shell&quot;&gt;#&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt; This part can be left out&lt;&#x2F;span&gt;&lt;span class=&quot;z-comment z-line z-number-sign z-shell&quot;&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;[tool.poetry.group.test.dependencies]&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;pytest&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; = &lt;span class=&quot;z-string z-quoted z-double z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-shell&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;^6.0.0&lt;span class=&quot;z-punctuation z-definition z-string z-end z-shell&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;pytest-mock&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; = &lt;span class=&quot;z-string z-quoted z-double z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-shell&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;*&lt;span class=&quot;z-punctuation z-definition z-string z-end z-shell&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This groups libraries like &lt;code&gt;pytest&lt;&#x2F;code&gt; and &lt;code&gt;pytest-mock&lt;&#x2F;code&gt; under the &lt;code&gt;test&lt;&#x2F;code&gt; group.&lt;&#x2F;p&gt;
&lt;p&gt;The Poetry documentation states:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Dependency groups (except the implicit &lt;strong&gt;&lt;code&gt;main&lt;&#x2F;code&gt;&lt;&#x2F;strong&gt; group) should include only the packages you need during development. They are installed only with Poetry. To declare a set of dependencies that add optional features at runtime, use &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;python-poetry.org&#x2F;docs&#x2F;pyproject&#x2F;#extras&quot;&gt;extras&lt;&#x2F;a&gt;. End users can install extras using pip.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Adding Dependencies to a Group&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When using &lt;code&gt;poetry add&lt;&#x2F;code&gt;, add the &lt;code&gt;--group&lt;&#x2F;code&gt; (or &lt;code&gt;-G&lt;&#x2F;code&gt;) parameter&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; add pytest&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;group&lt;&#x2F;span&gt; test&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If the dependency group does not exist, it will be created automatically.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Removing Dependencies from a Group&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Use &lt;code&gt;poetry remove&lt;&#x2F;code&gt; to delete packages from a specific group&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; remove mkdocs&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;group&lt;&#x2F;span&gt; docs&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Creating Optional Groups&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You can add &lt;code&gt;optional = true&lt;&#x2F;code&gt; to mark a group as optional, so that it is not automatically installed with &lt;code&gt;poetry install&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml z-code&quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-begin z-toml&quot;&gt;[&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-tag z-table z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;tool&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;group&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;docs&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-end z-toml&quot;&gt;]&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-meta z-tag z-key z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-tag z-toml&quot;&gt;optional&lt;&#x2F;span&gt;&lt;&#x2F;span&gt; &lt;span class=&quot;z-punctuation z-definition z-key-value z-toml&quot;&gt;=&lt;&#x2F;span&gt; &lt;span class=&quot;z-constant z-language z-toml&quot;&gt;true&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-begin z-toml&quot;&gt;[&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-tag z-table z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;tool&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;group&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;docs&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-separator z-table z-toml&quot;&gt;.&lt;&#x2F;span&gt;&lt;span class=&quot;z-entity z-name z-table z-toml&quot;&gt;dependencies&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-punctuation z-definition z-table z-end z-toml&quot;&gt;]&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-toml&quot;&gt;&lt;span class=&quot;z-meta z-tag z-key z-toml&quot;&gt;&lt;span class=&quot;z-entity z-name z-tag z-toml&quot;&gt;mkdocs&lt;&#x2F;span&gt;&lt;&#x2F;span&gt; &lt;span class=&quot;z-punctuation z-definition z-key-value z-toml&quot;&gt;=&lt;&#x2F;span&gt; &lt;span class=&quot;z-string z-quoted z-double z-basic z-toml&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-string z-begin z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;*&lt;span class=&quot;z-punctuation z-definition z-string z-end z-toml&quot;&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Installing&#x2F;Excluding Groups&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;By default, all groups except those marked optional are installed automatically with &lt;code&gt;poetry install&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;You can specify which dependency groups to include or exclude using the &lt;code&gt;--with&lt;&#x2F;code&gt; or &lt;code&gt;--without&lt;&#x2F;code&gt; options&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;with&lt;&#x2F;span&gt; docs&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;without&lt;&#x2F;span&gt; test,docs&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When used together, &lt;code&gt;--without&lt;&#x2F;code&gt; takes precedence over &lt;code&gt;--with&lt;&#x2F;code&gt;. For example, the following command will install only the dependencies specified in the optional &lt;code&gt;test&lt;&#x2F;code&gt; group.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;with&lt;&#x2F;span&gt; test,docs&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;without&lt;&#x2F;span&gt; docs&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you want to install only the runtime dependencies of the project, use the &lt;code&gt;--only main&lt;&#x2F;code&gt; option:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;only&lt;&#x2F;span&gt; main&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you want to install only the package at the project‚Äôs root and skip other dependencies, use the &lt;code&gt;--only-root&lt;&#x2F;code&gt; option.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;only-root&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Synchronization ‚Äì Installing Dependencies and Removing Unnecessary Packages&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Poetry supports dependency synchronization, which ensures that the dependencies locked in the &lt;strong&gt;&lt;code&gt;poetry.lock&lt;&#x2F;code&gt;&lt;&#x2F;strong&gt; file are the only ones present in your environment by removing any unneeded packages.&lt;&#x2F;p&gt;
&lt;p&gt;You can use the &lt;code&gt;--sync&lt;&#x2F;code&gt; parameter with &lt;code&gt;poetry install&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;sync&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This command will:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Remove extra packages&lt;&#x2F;li&gt;
&lt;li&gt;Install missing packages&lt;&#x2F;li&gt;
&lt;li&gt;Update outdated packages&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;It can be combined with the &lt;code&gt;--with&lt;&#x2F;code&gt; or &lt;code&gt;--without&lt;&#x2F;code&gt; options&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash z-code&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;without&lt;&#x2F;span&gt; dev&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;sync&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;with&lt;&#x2F;span&gt; docs&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;sync&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;span class=&quot;z-source z-shell z-bash&quot;&gt;&lt;span class=&quot;z-meta z-function-call z-shell&quot;&gt;&lt;span class=&quot;z-variable z-function z-shell&quot;&gt;poetry&lt;&#x2F;span&gt;&lt;&#x2F;span&gt;&lt;span class=&quot;z-meta z-function-call z-arguments z-shell&quot;&gt; install&lt;span class=&quot;z-variable z-parameter z-option z-shell&quot;&gt;&lt;span class=&quot;z-punctuation z-definition z-parameter z-shell&quot;&gt; --&lt;&#x2F;span&gt;only&lt;&#x2F;span&gt; dev&lt;&#x2F;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The primary dependencies are always installed. For example, if you have groups [main], [dev], [docs] and run &lt;code&gt;poetry install --with docs --sync&lt;&#x2F;code&gt;, then [main] and [docs] will be installed while [dev] will be omitted.&lt;&#x2F;p&gt;
</content>
        <summary type="html">Poetry installation and usage</summary>
        </entry><entry xml:lang="en">
        <title>LLM Scaling Laws Paper Excerpt - Scaling Laws for Neural Language Models</title>
        <published>2024-03-20T00:00:00+00:00</published>
        <updated>2024-03-20T00:00:00+00:00</updated>
        <author>
            <name>Jingxi Qiu</name>
        </author>
        <link rel="alternate" href="https://website.jingxiqiu.com/blog/scaling-law/" type="text/html"/>
        <id>https://website.jingxiqiu.com/blog/scaling-law/</id>
        
            <content type="html">&lt;h1 id=&quot;llm-scaling-laws-paper-excerpt-scaling-laws-for-neural-language-models&quot;&gt;LLM Scaling Laws Paper Excerpt - Scaling Laws for Neural Language Models&lt;&#x2F;h1&gt;
&lt;p&gt;type: Post
status: Published
date: 2024&#x2F;03&#x2F;20
tags: AI, LLM, NLP, ËÆ∫ÊñáÊëòÂΩï
category: ÊäÄÊúØÂàÜ‰∫´&lt;&#x2F;p&gt;
&lt;aside&gt;
‚úã Many people believe that the performance of large models is related to the model&#x27;s structure, size, training compute, and dataset size. However, how exactly do these factors influence the final performance of a large model? Understanding this can help in better deciding where to invest resources to train the required models.
&lt;&#x2F;aside&gt;
&lt;h1 id=&quot;background-and-content&quot;&gt;Background and Content&lt;&#x2F;h1&gt;
&lt;p&gt;In 2020, OpenAI released the paper ‚ÄúScaling Laws for Neural Language Models,‚Äù exploring Scaling Laws. This paper discusses the relationship between the training loss of large models based on Transformers and the model parameter size (N), dataset size (D), and computational volume (C).&lt;&#x2F;p&gt;
&lt;p&gt;In April 2022, Google DeepMind revisited Scaling Laws in their article ‚ÄúTraining Compute-Optimal Large Language Models.‚Äù They pointed out that current large models are significantly under-trained. By using four times the data (compared to the 280B parameter Gopher) to train the 70B parameter Chinchilla, they achieved better results (SOTA average accuracy of 67.5% on the MMLU benchmark, a 7% increase).&lt;&#x2F;p&gt;
&lt;p&gt;However, in February 2023, a blog titled ‚ÄúChinchilla‚Äôs Death‚Äù by &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;espadrine.github.io&#x2F;&quot;&gt;&lt;em&gt;Thadd√©e Tyl&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; argued that with sufficient training time, small models can outperform large models.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;paper&quot;&gt;Paper&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;scaling-laws-for-neural-language-models&quot;&gt;Scaling Laws for Neural Language Models&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;key-findings&quot;&gt;Key Findings&lt;&#x2F;h3&gt;
&lt;ol&gt;
&lt;li&gt;Model performance improves with the increase in model size (N), dataset size (D), and compute (C), and is weakly correlated with the model‚Äôs shape (depth and width) and the number of self-attention heads.&lt;&#x2F;li&gt;
&lt;li&gt;When other factors are not limited, there is a power-law relationship between model size (N), dataset size (D), compute (C), and performance.&lt;&#x2F;li&gt;
&lt;li&gt;Expanding both model size (N) and dataset size (D) simultaneously can improve model performance. However, the study suggests that when the model size increases eightfold, the dataset size only needs to increase fivefold, and this will not incur a performance penalty.&lt;&#x2F;li&gt;
&lt;li&gt;Because the training curve follows a power-law relationship, the loss is independent of model size, allowing us to roughly predict the loss for subsequent training.&lt;&#x2F;li&gt;
&lt;li&gt;There is a penalty (greater error) when transferring to a dataset different from the training set, but this penalty is constant, meaning other improvements are consistent.&lt;&#x2F;li&gt;
&lt;li&gt;Large models have higher sample efficiency compared to smaller models, requiring less training (Figure 2) and less data (Figure 4) to achieve the same level of performance.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;website.jingxiqiu.com&#x2F;blog&#x2F;scaling-law&#x2F;Untitled.png&quot; alt=&quot;Untitled&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;website.jingxiqiu.com&#x2F;blog&#x2F;scaling-law&#x2F;Untitled%201.png&quot; alt=&quot;Untitled&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Convergence is inefficient. When the compute (C) is fixed, it is possible to stop training before the model fully converges to achieve optimal performance (Figure 3). The paper provides a reference relationship as follows: $D\sim C^{0.27}$&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;website.jingxiqiu.com&#x2F;blog&#x2F;scaling-law&#x2F;Untitled%202.png&quot; alt=&quot;This figure illustrates the contributions of different factors under the same compute budget (C). Firstly, model size contributes the most, followed by data (achieved through larger batch sizes and reduced data reuse), while increasing the number of serial steps (more training iterations) does not significantly help.&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This figure illustrates the contributions of different factors under the same compute budget (C). Firstly, model size contributes the most, followed by data (achieved through larger batch sizes and reduced data reuse), while increasing the number of serial steps (more training iterations) does not significantly help.&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The ideal batch size for training should be proportional to the power of the training data size and can be further determined using the gradient noise scale.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;scaling-law-summary&quot;&gt;Scaling Law Summary&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;ParametersÔºö&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;non-embedding parameters $N$&lt;&#x2F;p&gt;
&lt;p&gt;the dataset size $D$&lt;&#x2F;p&gt;
&lt;p&gt;optimally allocated compute budget $C_{min}$&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Parameter Definition&lt;&#x2F;strong&gt;
&lt;ul&gt;
&lt;li&gt;$L$ ‚Äì the cross entropy loss in nats. Typically it will be averaged over the tokens in a context, but in some cases we report the loss for specific tokens within the context.&lt;&#x2F;li&gt;
&lt;li&gt;$N$ ‚Äì the number of model parameters, excluding all vocabulary and positional embeddings&lt;&#x2F;li&gt;
&lt;li&gt;$C$ $‚âà 6NBS$ ‚Äì an estimate of the total non-embedding training compute, where $B$ is the batch size, and $S$ is the number of training steps (ie parameter updates). We quote numerical values in PF-days, where one $\text{PF-day}= 10^{15} √ó 24 √ó 3600 = 8.64 √ó 10^{19}$ floating point operations.&lt;&#x2F;li&gt;
&lt;li&gt;$D$ ‚Äì the dataset size in tokens&lt;&#x2F;li&gt;
&lt;li&gt;$B_{crit}$ ‚Äì the critical batch size [MKAT18], defined and discussed in Section 5.1. Training at the critical batch size provides a roughly optimal compromise between time and compute efficiency.&lt;&#x2F;li&gt;
&lt;li&gt;$C_{min}$ ‚Äì an estimate of the minimum amount of non-embedding compute to reach a given value of the loss. This is the training compute that would be used if the model were trained at a batch size much less than the critical batch size.&lt;&#x2F;li&gt;
&lt;li&gt;$S_{min}$ ‚Äì an estimate of the minimal number of training steps needed to reach a given value of the loss. This is also the number of training steps that would be used if the model were trained at a batch size much greater than the critical batch size.&lt;&#x2F;li&gt;
&lt;li&gt;$\alpha_X$ ‚Äì power-law exponents for the scaling of the loss as $L(X) ‚àù 1&#x2F;X^{Œ±_X}$ where X can be any of $N, D, C, S, B, C^{min}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;When the other two factors are not limited, the test loss can be predicted using the following formula:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;N is limited&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;$$
\begin{equation} L(N)=(N_c&#x2F;N)^{\alpha_N} \end{equation}&lt;br &#x2F;&gt;
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
\alpha_N \sim 0.076,N_c \sim 8.8 \times 10^{13} \text{(non-embedding parameters)}
$$&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;D is limitedÔºàwith early stopping)&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;$$
\begin{equation} L(D)=(D_c&#x2F;D)^{\alpha_D} \end{equation}
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
\alpha_D \sim 0.095, D_c \sim 5.4 \times 10^{13}\text{(tokens)}
$$&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;C is limited&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;$$
\begin{equation}L(C_{min})=(C^{min}&lt;em&gt;c&#x2F;C&lt;&#x2F;em&gt;{min})^{\alpha_{min}} \end{equation}
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
\alpha_C^{min} \sim 0.050, C^{min}_c \sim 3.1 \times 10^8 \text{(PF-days)}
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Formula Meaning:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In the above formulas, $\alpha_N, \alpha_D, \alpha_C^{min}$ indicate the power law exponents that describe the performance improvement when increasing $N,D,C_{min}$.&lt;&#x2F;p&gt;
&lt;p&gt;For example, if we double the number of model parameters, the model loss will decrease by a factor of $2_{-\alpha_N}\approx 0.95$, meaning the loss will be 0.95 times the previous value. The exact numbers for $N_C,D_C,C_C^{min}$ are based on vocabulary size and tokenization, thus only representing an order of magnitude relationship rather than precise values.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, the paper discusses the relationship between batch size and loss.&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{equation}B_{crit}(L)=\frac{B_*}{L^{1&#x2F;a_B}} \end{equation}
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
B_* \sim 2\cdot10^8 \text{tokens}, \alpha_B\sim0.21
$$&lt;&#x2F;p&gt;
&lt;p&gt;Based on the previous formulas (1) and (2), when we increase the model size, we should correspondingly increase the dataset size. It can be calculated as:$D\propto N^{\frac{\alpha_{N}}{\alpha_D}} \sim N^{0.74}$„ÄÇ&lt;&#x2F;p&gt;
&lt;p&gt;They also derived a combined formula from (1) and (2) to manage the dependencies of N and D and to control overfitting:&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{equation}L(N,D)=\left[\left(\frac{N_c}{N}^{\frac{\alpha_N}{\alpha_D}}+\frac{D_c}{D} \right)  \right]^{\alpha_D}\end{equation}
$$&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;The authors speculate that this function can also generate the maximum log-likelihood for other generative tasks.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The training curve can also be derived from the number of training steps, allowing us to determine the optimal number of training steps.&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{equation}L(N,S)=\left(\frac{N_c}{N}\right)^{\alpha{N}}+\left(\frac{S_c}{S_{min}(S)}\right)^{\alpha_S}\end{equation}
$$&lt;&#x2F;p&gt;
&lt;p&gt;$S_c \approx 2.1 \times 10^3,\alpha_S \approx 0.76$
$S_{min}(S)$ is the minimum possible number of optimization steps (parameter updates) estimated using Equation&lt;&#x2F;p&gt;
&lt;p&gt;In the case of fixed compute C, the following relationship formula is derived:&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{equation}N \propto C^{\alpha^{min}_C &#x2F;\alpha_N}, B \propto C^{\alpha^{min}_C &#x2F;\alpha_B}, S \propto C^{\alpha^{min}_C &#x2F;\alpha_S}, D = B \cdot S\end{equation}
$$&lt;&#x2F;p&gt;
&lt;p&gt;Here we have:&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{equation}\alpha^{min}_C=1&#x2F;(1&#x2F;\alpha_S+1&#x2F;\alpha_B+1&#x2F;\alpha_N)\end{equation}
$$&lt;&#x2F;p&gt;
&lt;p&gt;So we can get $N \propto C^{0.73}&lt;em&gt;{min}, B \propto C^{0.24}&lt;&#x2F;em&gt;{min},\text{ and }S \propto C^{0.03}_{min}$Ôºåhere drop out the ideasÔºö&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When the compute budget C is increased, it should primarily be used to create larger models rather than extending training time or increasing dataset size.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Additionally, as models become larger, they become more sample efficient.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;research-methodology&quot;&gt;Research Methodology&lt;&#x2F;h3&gt;
&lt;p&gt;The study was conducted using the WebText2 dataset and its extension (2.29 √ó 10^10 tokens). The tokenization method employed was byte-pair encoding, with a vocabulary size of $n_{vocab}=50257$. The performance metric (Loss) was the cross-entropy loss over a context of 1024 tokens. The primary model used was a decoder-only Transformer, and LSTM along with other types of Transformers were also trained for comparison.&lt;&#x2F;p&gt;
&lt;p&gt;Unless otherwise specified, the model training utilized the Adam optimizer for $2.5 \times 10^5$ steps with a batch size of 512 and a context of 512 tokens. Due to memory constraints, the largest models were trained using the Adafactor optimizer.&lt;&#x2F;p&gt;
&lt;p&gt;The learning rate schedule, unless otherwise noted, included a warm-up period of 3000 steps followed by cosine decay to zero.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Model Parameter Calculation Method&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To calculate the model parameters and compute requirements, the model hyperparameters are defined as follows:&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Symbol&lt;&#x2F;th&gt;&lt;th&gt;Description&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;$n_{layer}$&lt;&#x2F;td&gt;&lt;td&gt;Number of layers&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;$d_{model}$&lt;&#x2F;td&gt;&lt;td&gt;Dimension of the residual stream&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;$d_{ff}$&lt;&#x2F;td&gt;&lt;td&gt;Dimension of the intermediate feed-forward layer&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;$d_{attn}$&lt;&#x2F;td&gt;&lt;td&gt;Dimension of the attention output&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;$n_{heads}$&lt;&#x2F;td&gt;&lt;td&gt;Number of attention heads per layer&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;$n_{ctx}$&lt;&#x2F;td&gt;&lt;td&gt;Number of input context tokens (typically 1024)&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;$N$ to represent the size of the model parameters, excluding the embedding layers, the calculation for model parameters is as follows:&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{aligned} N&amp;amp;\approx 2d_{model}n_{layer}(2d_{attn}+d_{ff}) \ &amp;amp;= 12n_{layer}d^2_{model}\end{aligned}
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
d_{attn}=d_{ff}&#x2F;4=d_{model}
$$&lt;&#x2F;p&gt;
&lt;p&gt;Here, the parameters for the embedding layers $n_{vocab}d_{model}$ and $n_{ctx}d_{model}$ are omitted.&lt;&#x2F;p&gt;
&lt;p&gt;The compute required for a forward pass, denoted as $C$, is approximately:&lt;&#x2F;p&gt;
&lt;p&gt;$$
C_{forward} \approx 2N+2n_{layer}n_{ctx}d_{model}
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;website.jingxiqiu.com&#x2F;blog&#x2F;scaling-law&#x2F;Untitled%203.png&quot; alt=&quot;Untitled&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;experimental-results&quot;&gt;Experimental Results&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;Experimental Variables:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Model Size:&lt;&#x2F;strong&gt; Ranging from 768 non-embedding parameters to 1.5 billion parameters.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Dataset Size:&lt;&#x2F;strong&gt; From 22 million to 23 billion tokens.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Model Shape:&lt;&#x2F;strong&gt; Including variations in depth, width, attention heads, and feed-forward dimensions.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Context Length:&lt;&#x2F;strong&gt; Typically 1024 tokens, but shorter contexts were also tested.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Batch Size:&lt;&#x2F;strong&gt; Typically $2^{19}$, but varied to measure the critical batch size.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;website.jingxiqiu.com&#x2F;blog&#x2F;scaling-law&#x2F;Untitled%204.png&quot; alt=&quot;Untitled&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;website.jingxiqiu.com&#x2F;blog&#x2F;scaling-law&#x2F;Untitled%205.png&quot; alt=&quot;Untitled&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;When the non-embedding model size $N$ is fixed, the model shape has a minimal impact on performance, with large adjustments affecting performance by only a few percentage points.&lt;&#x2F;li&gt;
&lt;li&gt;If the embedding parameters are included, model performance shows a significant correlation with the number of layers (left graph). However, if the embedding parameters are excluded, the performance of models with different numbers of layers follows the same trend, except for models with fewer than two layers (right graph).&lt;&#x2F;li&gt;
&lt;li&gt;The same applies to LSTM models, although LSTM performance is slightly inferior to Transformers.&lt;&#x2F;li&gt;
&lt;li&gt;The power law theorem formula holds:&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;$$
\begin{aligned}
L(N)      &amp;amp;\approx (N_c&#x2F;N)^{\alpha_N} \
L(D)      &amp;amp;\approx (D_c&#x2F;D)^{\alpha_D} \
L(C_{min})&amp;amp;\approx (C_{c}^{min}&#x2F;C_{min})^{\alpha_{min}}
\end{aligned}
$$&lt;&#x2F;p&gt;
&lt;h1 id=&quot;can-kao&quot;&gt;ÂèÇËÄÉ&lt;&#x2F;h1&gt;
&lt;p&gt;[1] &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2001.08361.pdf&quot;&gt;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2001.08361.pdf&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[2] &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.15556.pdf&quot;&gt;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2203.15556.pdf&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[3] &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;espadrine.github.io&#x2F;blog&#x2F;posts&#x2F;chinchilla-s-death.html&quot;&gt;https:&#x2F;&#x2F;espadrine.github.io&#x2F;blog&#x2F;posts&#x2F;chinchilla-s-death.html&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[4] &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2109.10686.pdf&quot;&gt;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2109.10686.pdf&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;[5] &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;self-supervised.cs.jhu.edu&#x2F;sp2023&#x2F;files&#x2F;17.retrieval-augmentation.pdf&quot;&gt;https:&#x2F;&#x2F;self-supervised.cs.jhu.edu&#x2F;sp2023&#x2F;files&#x2F;17.retrieval-augmentation.pdf&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        <summary type="html">LLM Scaling Laws Paper Excerpt - Scaling Laws for Neural Language Models</summary>
        </entry>
</feed>
